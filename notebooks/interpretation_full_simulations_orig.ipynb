{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "\n",
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.io\n",
    "import scipy.signal\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "from torch.autograd import Variable\n",
    "import torch, torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import scipy\n",
    "import sklearn\n",
    "import sklearn.metrics\n",
    "import sklearn.linear_model\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.signal\n",
    "import random\n",
    "import scipy\n",
    "import math\n",
    "import pandas as pd\n",
    "\n",
    "import sklearn\n",
    "import sklearn.linear_model\n",
    "\n",
    "import colorednoise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.signal\n",
    "import random\n",
    "import scipy\n",
    "import math\n",
    "\n",
    "import colorednoise\n",
    "\n",
    "\n",
    "def data_generator(X, Y, batch_size, lag_backward, lag_forward, shuffle = True, infinite = True):\n",
    "    assert len(X)==len(Y) or len(Y)==0, f\"{len(X)}!={len(Y)} and {len(Y)}==0\"\n",
    "    total_lag = lag_backward + lag_forward\n",
    "    all_batches = math.ceil((X.shape[0] - total_lag)/batch_size)\n",
    "    samples_in_last_batch = (X.shape[0] - total_lag) % batch_size\n",
    "    batch = 0\n",
    "    random_core = np.arange(lag_backward, X.shape[0]-lag_forward)\n",
    "    while True:\n",
    "        if shuffle: np.random.shuffle(random_core)\n",
    "        for batch in range(all_batches):       \n",
    "            batch_start = batch*batch_size\n",
    "            batch_end = (batch+1)*batch_size\n",
    "            if batch_end>=len(random_core): batch_end = None\n",
    "            batch_samples = random_core[batch_start : batch_end]\n",
    "\n",
    "            batch_x = np.array([X[i - lag_backward : i + lag_forward] for i in batch_samples])\n",
    "            batch_x = np.swapaxes(batch_x,1,2)\n",
    "\n",
    "            if len(Y) > 0:\n",
    "                batch_y = Y[[batch_samples]] \n",
    "                yield (batch_x, batch_y)\n",
    "            else:\n",
    "                yield batch_x\n",
    "        \n",
    "        if not infinite:\n",
    "            break\n",
    "\n",
    "def generate_random_filters(number_of_filters, lower_frequency, upper_frequency, filters_broadband, frequency):\n",
    "    filters_lower_bands = np.random.uniform(lower_frequency, upper_frequency, filters_broadband)\n",
    "    filters_upper_bands = [min(lower_band + filters_broadband, int(frequency / 2)) for lower_band in filters_lower_bands]\n",
    "    assert(len(filters_lower_bands) == len(filters_upper_bands))\n",
    "    filters = []\n",
    "    for filter_lower_band, filter_upper_band in zip(filters_lower_bands, filters_upper_bands):\n",
    "        single_filter = scipy.signal.firwin(34, [filter_lower_band, filter_upper_band], fs=frequency, pass_zero=False)\n",
    "    return filters\n",
    "\n",
    "\n",
    "def filter_signals(signals, filters):\n",
    "    number_of_signals = signals.shape[1]\n",
    "    assert number_of_signals == len(filters)\n",
    "    filtered_signals = np.copy(signals)\n",
    "    for index, single_filter in enumerate(filters):\n",
    "        if single_filter is None:\n",
    "            filtered_signals[:, index] = signals[:, index]\n",
    "            continue\n",
    "        filtered_signals[:, index] = np.convolve(signals[:, index], single_filter, mode = \"same\")\n",
    "    return filtered_signals\n",
    "\n",
    "\n",
    "def envelope_signals(signals):\n",
    "    enveloped_signals = np.zeros(signals.shape)\n",
    "    for i in range(signals.shape[1]):\n",
    "        enveloped_signals[:, i] = np.abs(scipy.signal.hilbert(signals[:, i]))\n",
    "    return enveloped_signals\n",
    "\n",
    "\n",
    "def mix_signals(signals, output_dimension):\n",
    "    input_dimension = signals.shape[1]\n",
    "    mixing_matrix = np.random.uniform(0, 1, (input_dimension, output_dimension))\n",
    "    mixed_signals = np.matmul(signals, mixing_matrix)\n",
    "    return mixed_signals\n",
    "\n",
    "def get_spectrum(y, Fs):\n",
    "    n = len(y) # length of the signal\n",
    "    k = scipy.arange(n)\n",
    "    T = n/Fs\n",
    "    frq = k/T # two sides frequency range\n",
    "    frq = frq[range(int(n/2))] # one side frequency range\n",
    "\n",
    "    Y = scipy.fft(y)/n # fft computing and normalization\n",
    "    Y = Y[range(int(n/2))]\n",
    "    return abs(Y)\n",
    "\n",
    "def plotSpectrum(y, Fs):\n",
    "\n",
    "    n = len(y) # length of the signal\n",
    "    k = scipy.arange(n)\n",
    "    T = n/Fs\n",
    "    frq = k/T # two sides frequency range\n",
    "    frq = frq[range(int(n/2))] # one side frequency range\n",
    "\n",
    "    Y = scipy.fft(y)/n # fft computing and normalization\n",
    "    Y = Y[range(int(n/2))]\n",
    "    \n",
    "    plt.figure(figsize=(14, 1))\n",
    "    plt.plot(frq,abs(Y)) # plotting the spectrum\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "def make_lag(X, lag_backward, lag_forward):\n",
    "    assert(lag_backward >= 0)\n",
    "    assert(lag_forward >= 0)\n",
    "    X_lag_list = []\n",
    "    for i in reversed(range(1, lag_backward + 1)):\n",
    "        X_lag_list.append(X[lag_backward - i:-lag_forward - i if lag_forward + i > 0 else None])\n",
    "    X_lag_list.append(X[lag_backward:-lag_forward if lag_forward > 0 else None])\n",
    "    for i in range(1, lag_forward + 1):\n",
    "        X_lag_list.append(X[lag_backward + i:-lag_forward + i if lag_forward - i > 0 else None])\n",
    "    return np.concatenate(X_lag_list, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mixing_matrix:\n",
      " [[0.33384428 0.06322857 0.06471068 0.16772285]\n",
      " [0.18286733 0.18788121 0.16565825 0.55860323]\n",
      " [0.04175425 0.67152578 0.42231403 0.77706902]\n",
      " [0.08697226 0.94362509 0.01462183 0.53486307]\n",
      " [0.58261606 0.77526983 0.71845051 0.26313062]]\n"
     ]
    }
   ],
   "source": [
    "RANDOM_SEED = 67\n",
    "\n",
    "FREQUENCY = 1000\n",
    "\n",
    "signals_length = 2000000\n",
    "sources_dimension = 4\n",
    "noises_dimension = 40\n",
    "sensors_dimension = 5\n",
    "output_dimension = 4\n",
    "target_lag = 5\n",
    "BETA = 1\n",
    "\n",
    "minor_noise = colorednoise.powerlaw_psd_gaussian(BETA, signals_length * sensors_dimension).reshape((signals_length, sensors_dimension))\n",
    "\n",
    "\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "signals = np.random.normal(0, 1, (signals_length, sources_dimension))\n",
    "filters = [\n",
    "    scipy.signal.firwin(100, [30, 80], fs=FREQUENCY, pass_zero=False),\n",
    "    scipy.signal.firwin(100, [80, 120], fs=FREQUENCY, pass_zero=False),\n",
    "    scipy.signal.firwin(100, [120, 170], fs=FREQUENCY, pass_zero=False),\n",
    "    scipy.signal.firwin(100, [170, 220], fs=FREQUENCY, pass_zero=False),\n",
    "]\n",
    "assert len(filters) == sources_dimension\n",
    "filtered_signals = filter_signals(signals, filters)\n",
    "enveloped_signals = envelope_signals(filtered_signals)\n",
    "mixing_matrix = np.random.uniform(0, 1, (sources_dimension, sensors_dimension))\n",
    "mixed_signals = np.matmul(filtered_signals, mixing_matrix)\n",
    "\n",
    "weight_matrix = np.random.uniform(0, 1, (target_lag, sources_dimension))\n",
    "target = scipy.signal.convolve2d(np.pad(enveloped_signals, pad_width=((2, 2), (0, 0)), mode=\"edge\",), weight_matrix, mode='valid')\n",
    "\n",
    "noisy_signals = colorednoise.powerlaw_psd_gaussian(BETA, signals_length * noises_dimension).reshape((signals_length, noises_dimension))\n",
    "np.random.normal(0, 1, (signals_length, noises_dimension))\n",
    "noisy_filters = [\n",
    "    scipy.signal.firwin(100, [40, 70], fs=FREQUENCY, pass_zero=False),\n",
    "    scipy.signal.firwin(100, [90, 110], fs=FREQUENCY, pass_zero=False),\n",
    "    scipy.signal.firwin(100, [130, 160], fs=FREQUENCY, pass_zero=False),\n",
    "    scipy.signal.firwin(100, [180, 210], fs=FREQUENCY, pass_zero=False),\n",
    "] * 10\n",
    "\n",
    "assert len(noisy_filters) == noises_dimension, f'{len(noisy_filters)} != {noises_dimension}'\n",
    "filtered_noisy_signals = filter_signals(noisy_signals, noisy_filters)\n",
    "noise_mixing_matrix = np.random.uniform(0, 1, (noises_dimension, sensors_dimension))\n",
    "mixed_noises = np.matmul(filtered_noisy_signals, noise_mixing_matrix)\n",
    "\n",
    "noisy_input = mixed_signals + 1 * mixed_noises  + 0.1 * minor_noise\n",
    "\n",
    "\n",
    "X = noisy_input\n",
    "Y = target\n",
    "\n",
    "assert len(X) == len(Y), f\"{len(X)} != {len(Y)}\"\n",
    "assert np.linalg.matrix_rank(X) == sensors_dimension\n",
    "\n",
    "X_original = np.copy(X)\n",
    "X_scaler = sklearn.preprocessing.StandardScaler()\n",
    "Y_scaler = sklearn.preprocessing.StandardScaler()\n",
    "\n",
    "X = X_scaler.fit_transform(X)\n",
    "Y = Y_scaler.fit_transform(Y)\n",
    "\n",
    "NTR = int(signals_length / 2)\n",
    "\n",
    "train_slice = slice(None, NTR)\n",
    "test_slice = slice(NTR, None)\n",
    "\n",
    "X_train = X[train_slice, :]\n",
    "Y_train = Y[train_slice, :]\n",
    "\n",
    "X_test = X[test_slice, :]\n",
    "Y_test = Y[test_slice, :]\n",
    "\n",
    "\n",
    "def get_weights(X, Y, intercept=False):\n",
    "    if intercept:\n",
    "        X = np.concatenate([np.ones(X.shape[0]).reshape((-1, 1)), X], axis=1)\n",
    "    return np.linalg.multi_dot([np.linalg.inv(np.matmul(X.transpose(), X)), X.transpose(), Y])[int(intercept):]\n",
    "\n",
    "\n",
    "def get_interpretable(X, W, Y):\n",
    "    y_col = Y.shape[1]\n",
    "    return np.linalg.multi_dot([\n",
    "        np.cov(X, rowvar=False), \n",
    "        W, \n",
    "        np.linalg.inv(np.cov(Y, rowvar=False).reshape((y_col, y_col)))\n",
    "    ])\n",
    "\n",
    "\n",
    "def compare_weights(interpret):\n",
    "    for i in range(sources_dimension):\n",
    "        print(round(np.corrcoef(interpret[:, i], mixing_matrix[i, :], rowvar=False)[0, 1], 3), end=\"\\t\")\n",
    "    print()\n",
    "\n",
    "\n",
    "print(\"mixing_matrix:\\n\", mixing_matrix.transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class envelope_detector(nn.Module):\n",
    "    def __init__(self, in_channels, channels_per_channel):\n",
    "        super(self.__class__,self).__init__()\n",
    "        self.FILTERING_SIZE = 100\n",
    "        self.ENVELOPE_SIZE = 100\n",
    "        self.CHANNELS_PER_CHANNEL = channels_per_channel\n",
    "        self.OUTPUT_CHANNELS = self.CHANNELS_PER_CHANNEL * in_channels\n",
    "        self.pre_envelope_batchnorm = torch.nn.BatchNorm1d(self.OUTPUT_CHANNELS, affine=False)\n",
    "        self.conv_filtering = nn.Conv1d(in_channels, self.OUTPUT_CHANNELS, bias=False, kernel_size=self.FILTERING_SIZE, groups=in_channels)\n",
    "        self.conv_envelope = nn.Conv1d(self.OUTPUT_CHANNELS, self.OUTPUT_CHANNELS, kernel_size=self.ENVELOPE_SIZE, groups=self.OUTPUT_CHANNELS)\n",
    "        self.conv_out = None\n",
    "        self.features = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_filtering(x)\n",
    "        self.features = x.cpu().data.numpy()\n",
    "        self.conv_out = x.cpu().data.numpy()\n",
    "        x = self.pre_envelope_batchnorm(x)\n",
    "        x = torch.abs(x)\n",
    "        x = self.conv_envelope(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class simple_net(nn.Module):\n",
    "    def __init__(self, in_channels, output_channels, lag_backward, lag_forward):\n",
    "        super(self.__class__,self).__init__()\n",
    "        self.ICA_CHANNELS = sources_dimension\n",
    "        self.CHANNELS_PER_CHANNEL = 1\n",
    "\n",
    "        self.middle_point_share = lag_backward * 1.0 / (lag_backward + lag_forward)\n",
    "\n",
    "        self.ica = nn.Conv1d(in_channels, self.ICA_CHANNELS, 1)\n",
    "        \n",
    "        self.total_input_channels = self.ICA_CHANNELS\n",
    "        self.detector = envelope_detector(self.total_input_channels, self.CHANNELS_PER_CHANNEL)\n",
    "\n",
    "        self.final_out_features = sources_dimension * target_lag\n",
    "        self.wights_second = nn.Linear(self.final_out_features, output_channels)\n",
    "        self.fuck_channels = None\n",
    "        self.envelopes = None\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.ica(x)\n",
    "        self.fuck_channels = x.cpu().data.numpy()\n",
    "        x = self.detector(x)\n",
    "        middle_point = int((x.shape[-1]) * self.middle_point_share)\n",
    "        self.envelopes = x[:, :, middle_point].contiguous().cpu().data.numpy()\n",
    "        x = x[:, :, middle_point - int(target_lag /2):middle_point + int(target_lag /2)+1].contiguous()\n",
    "        #self.features = x.cpu().detach().numpy()\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.wights_second(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable params:  849\n",
      "Total params:  849\n"
     ]
    }
   ],
   "source": [
    "IS_UNMIXED_GET = False\n",
    "\n",
    "batch_size = 500\n",
    "lag_backward = 120\n",
    "lag_forward = 120\n",
    "\n",
    "model = simple_net(X_train.shape[1], Y_test.shape[1], lag_backward, lag_forward)\n",
    "\n",
    "\n",
    "print(\"Trainable params: \",sum(p.numel() for p in model.parameters() if p.requires_grad))\n",
    "print(\"Total params: \",sum(p.numel() for p in model.parameters() if p.requires_grad))\n",
    "loss_function = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.002)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_batch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mx_batch\u001b[49m\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x_batch' is not defined"
     ]
    }
   ],
   "source": [
    "x_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_39685/4038697638.py:3: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  pbar = tqdm_notebook()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02bd0037bbc24267b2e9938ffe8b785a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_39685/3702784876.py:30: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  batch_y = Y[[batch_samples]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation   test ###\n",
      "0.4757\t\n",
      "#############\n",
      "Correlation   test ###\n",
      "0.6537\t\n",
      "#############\n",
      "Correlation   test ###\n",
      "0.6804\t\n",
      "#############\n",
      "Correlation   test ###\n",
      "0.6874\t\n",
      "#############\n",
      "Correlation   test ###\n",
      "0.6903\t\n",
      "#############\n",
      "Correlation   test ###\n",
      "0.6959\t\n",
      "#############\n",
      "Correlation   test ###\n",
      "0.6987\t\n",
      "#############\n"
     ]
    }
   ],
   "source": [
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)\n",
    "loss_history = []\n",
    "pbar = tqdm_notebook()\n",
    "for x_batch, y_batch in data_generator(X_train, Y_train, batch_size, lag_backward, lag_forward):\n",
    "    model.train()\n",
    "    assert x_batch.shape[0]==y_batch.shape[0]\n",
    "    x_batch = Variable(torch.FloatTensor(x_batch))\n",
    "    y_batch = Variable(torch.FloatTensor(y_batch))\n",
    "    optimizer.zero_grad()\n",
    "    y_predicted = model(x_batch)\n",
    "    loss = loss_function(y_predicted, y_batch)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    loss_history.append(loss.cpu().data.numpy())    \n",
    "    pbar.update(1)\n",
    "    eval_lag = min(100,len(loss_history))\n",
    "    pbar.set_postfix(loss = np.mean(loss_history[-eval_lag:]))\n",
    "    \n",
    "    if len(loss_history) == 2000:\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr = 0.0005)\n",
    "\n",
    "    if len(loss_history) == 5000:\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr = 0.0003)\n",
    "        \n",
    "    if len(loss_history) == 7000:\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr = 0.0001)\n",
    "    \n",
    "    if len(loss_history) % 1000 == 0:\n",
    "        Y_sliced = Y_test[lag_backward:-lag_forward if lag_forward > 0 else None]\n",
    "        Y_predicted = []\n",
    "        for x_batch, y_batch in data_generator(X_test, Y_test, batch_size, lag_backward, lag_forward, shuffle=False, infinite= False):\n",
    "            model.eval()\n",
    "            assert x_batch.shape[0]==y_batch.shape[0]\n",
    "            x_batch = Variable(torch.FloatTensor(x_batch))\n",
    "            y_batch = Variable(torch.FloatTensor(y_batch))\n",
    "            y_predicted = model(x_batch).cpu().data.numpy()\n",
    "            Y_predicted.append(y_predicted)\n",
    "\n",
    "        Y_predicted = np.concatenate(Y_predicted, axis = 0)\n",
    "        print(\"Correlation   test ###\")\n",
    "        for i in range(Y_predicted.shape[1]):\n",
    "            print(round(np.corrcoef(Y_predicted[:, i], Y_sliced[:, i], rowvar=False)[0,1], 4), end=\"\\t\")\n",
    "            \n",
    "        print(\"\\n#############\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_sliced = Y_test[lag_backward:-lag_forward if lag_forward > 0 else None]\n",
    "enveloped_signals_sliced = enveloped_signals[test_slice, :][lag_backward:-lag_forward if lag_forward > 0 else None]\n",
    "Y_predicted = []\n",
    "envelopes = []\n",
    "for x_batch, y_batch in tqdm_notebook(data_generator(X_test, Y_test, batch_size, lag_backward, lag_forward, shuffle=False, infinite= False)):\n",
    "    model.eval()\n",
    "    assert x_batch.shape[0]==y_batch.shape[0]\n",
    "    x_batch = Variable(torch.FloatTensor(x_batch))\n",
    "    y_batch = Variable(torch.FloatTensor(y_batch))\n",
    "    y_predicted = model(x_batch).cpu().data.numpy()\n",
    "    Y_predicted.append(y_predicted)\n",
    "    envelopes.append(model.envelopes)\n",
    "\n",
    "envelopes = np.concatenate(envelopes, axis = 0)\n",
    "Y_predicted = np.concatenate(Y_predicted, axis = 0)\n",
    "print(\"Correlation   test ###\")\n",
    "for i in range(Y_predicted.shape[1]):\n",
    "    print(round(np.corrcoef(Y_predicted[:, i], Y_sliced[:, i], rowvar=False)[0,1], 2), end=\"\\t\")\n",
    "\n",
    "ZOOM = 500\n",
    "for i in range(Y_predicted.shape[1]):\n",
    "    plt.figure(figsize=(9, 1.5))\n",
    "    plt.rc('font', family='serif')\n",
    "    corr = np.corrcoef(Y_predicted[:, i], Y_sliced[:, i], rowvar=False)[0,1]\n",
    "    plt.title(str(int(corr * 100)) + \"% correlation\")\n",
    "    plt.plot(Y_sliced[:ZOOM, i], label = 'True',  color='0.40', ls=\"--\")\n",
    "    plt.plot(Y_predicted[:ZOOM, i], color='k', label = 'Predicted')\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "#fig.savefig(fname='target_not_perfect' + \".pdf\", format=\"pdf\", bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_unmixed = []\n",
    "X_filtered = []\n",
    "for x_batch in tqdm_notebook(\n",
    "    data_generator(X_train, [], batch_size, lag_backward, lag_forward, shuffle=False, infinite=False)\n",
    "):\n",
    "    #### Train\n",
    "    model.eval()\n",
    "    x_batch = Variable(torch.FloatTensor(x_batch))\n",
    "    y_predicted = model(x_batch).cpu().data.numpy()\n",
    "    X_unmixed.append(model.fuck_channels)\n",
    "    X_filtered.append(model.detector.conv_out)\n",
    "\n",
    "X_filtered = np.concatenate(X_filtered, axis = 0)[:, :, -1]\n",
    "X_unmixed = np.concatenate(X_unmixed, axis = 0)[:, :, -1]\n",
    "X_unmixed_copy = np.copy(X_unmixed)\n",
    "\n",
    "X_inputs = []\n",
    "for x_batch in tqdm_notebook(\n",
    "    data_generator(X_original, [], batch_size, lag_backward, lag_forward, shuffle=False, infinite=False)\n",
    "):\n",
    "    X_inputs.append(x_batch)\n",
    "X_inputs = np.concatenate(X_inputs, axis = 0)\n",
    "\n",
    "IS_UNMIXED_GET = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full = []\n",
    "for index, x_batch in tqdm_notebook(enumerate(data_generator(X_train, [], batch_size, lag_backward, lag_forward, shuffle=False, infinite= False))):\n",
    "    #### Train\n",
    "    if index % 50 == 0:\n",
    "        X_train_full.append(x_batch)\n",
    "\n",
    "X_train_full = np.concatenate(X_train_full, axis = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WEIGHTS_COLOR = \"k\"\n",
    "PATTENS_COLOR = \"#1f77b4\"\n",
    "TRUE_COLOR = \"#ff7f0e\"\n",
    "PATTERNS_NAIVE_COLOR = \"#d62728\"\n",
    "\n",
    "WEIGHTS_MARKER = \".\"\n",
    "PATTENS_MARKER = \"v\"\n",
    "TRUE_MARKER = \"o\"\n",
    "PATTERNS_NAIVE_MARKER = \"P\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(IS_UNMIXED_GET)\n",
    "\n",
    "X_unmixed = np.copy(X_unmixed_copy)\n",
    "\n",
    "KOSTYL_CHOOSE = [0, 2, 1, 3]\n",
    "KOSTYL_CHOOSE_BOOL = True\n",
    "\n",
    "NPERSEQ = 1000\n",
    "\n",
    "\n",
    "def get_freq_domain(signal, frequency):\n",
    "    n = NPERSEQ\n",
    "    ampletude = np.abs(np.fft.fft(signal,n))\n",
    "    frequencies = np.fft.fftfreq(n , 1 / frequency)\n",
    "    assert len(ampletude) == len(frequencies), f\"{len(ampletude)}!={len(frequencies)}\"\n",
    "    end = int(len(frequencies)/2)\n",
    "    return frequencies[:end], ampletude[:end]\n",
    "\n",
    "\n",
    "Y_sliced = Y_train[lag_backward:-lag_forward if lag_forward > 0 else None]\n",
    "\n",
    "\n",
    "unmixed_channels_number = int(X_unmixed.shape[1])\n",
    "convs_weights = list(model.detector.conv_filtering.cpu().parameters())[0].detach().numpy()\n",
    "ica_weights = model.ica.weight.cpu().detach().numpy()[:, :, 0].transpose()\n",
    "ica_weights_scaled = ica_weights * (1 / np.sqrt(X_scaler.var_.reshape(-1, 1)))\n",
    "\n",
    "if KOSTYL_CHOOSE_BOOL:\n",
    "    # learned patterns can be permutated. here we manually need to fix it\n",
    "    convs_weights = convs_weights[KOSTYL_CHOOSE,:,:]\n",
    "    ica_weights = ica_weights[:,KOSTYL_CHOOSE]\n",
    "    ica_weights_scaled = ica_weights_scaled[:,KOSTYL_CHOOSE]\n",
    "    X_unmixed = X_unmixed[:, KOSTYL_CHOOSE]\n",
    "assert convs_weights.shape[0] % unmixed_channels_number == 0\n",
    "filters_per_channel = int(convs_weights.shape[0] / unmixed_channels_number)\n",
    "\n",
    "anal_data = []\n",
    "for unmixed_channel_number in range(unmixed_channels_number):\n",
    "    for filter_number in range(filters_per_channel):\n",
    "        anal_data.append(\n",
    "            (\n",
    "                unmixed_channel_number,\n",
    "                filter_number,\n",
    "                X_unmixed[:, unmixed_channel_number],\n",
    "                convs_weights[unmixed_channel_number * filters_per_channel + filter_number, 0, :],\n",
    "            )\n",
    "        )\n",
    "\n",
    "scaled_ampletude = np.zeros(500)\n",
    "scaled_recovered = np.zeros(500)\n",
    "scaled_input = np.zeros(500)\n",
    "COMPARISON_TOLERANCE = 10\n",
    "ZOOM = 250\n",
    "\n",
    "\n",
    "FINAL_FUGURE, FINAL_AXIS = plt.subplots(4, 2)\n",
    "FINAL_FUGURE.set_figwidth(12)\n",
    "FINAL_FUGURE.set_figheight(6)\n",
    "plt.rc('font', family='serif', size=12)\n",
    "FINAL_FUGURE.tight_layout()\n",
    "\n",
    "\n",
    "for i in range(1, 5):\n",
    "    plt.setp(FINAL_AXIS[i-1 , 0], ylabel=f\"Branch {i}\")\n",
    "    \n",
    "plt.setp(FINAL_AXIS[3, 0], xlabel='Frequency, Hz')\n",
    "\n",
    "\n",
    "FINAL_AXIS[0, 0].set_title('Temporal Patterns')\n",
    "FINAL_AXIS[0, 1].set_title('Spatial Patterns')\n",
    "\n",
    "\n",
    "for index in range(len(anal_data)):\n",
    "    unmixed_channel_number, filter_number, unmiex_input_signal, weights = anal_data[index]\n",
    "\n",
    "    frequencies_input, spectrum_input = scipy.signal.welch(X_unmixed[:, unmixed_channel_number], FREQUENCY, nperseg=NPERSEQ, detrend='linear')\n",
    "    frequencies_input = frequencies_input[:-1]\n",
    "    spectrum_input = spectrum_input[:-1]\n",
    "    \n",
    "    frequencies, ampletude = get_freq_domain(weights, FREQUENCY)\n",
    "    frequencies_true, ampletude_true = get_freq_domain(filters[unmixed_channel_number], FREQUENCY)\n",
    "    end = int(len(frequencies)/2)\n",
    "\n",
    "    assert len(frequencies_input) == len(frequencies), f\"{len(frequencies_input)}!={len(frequencies)}\"\n",
    "    assert(\n",
    "        list(np.round(frequencies_input, COMPARISON_TOLERANCE)) ==\\\n",
    "        list(np.round(frequencies, COMPARISON_TOLERANCE))\n",
    "    )\n",
    "\n",
    "    recovered = np.power(sklearn.preprocessing.minmax_scale(ampletude), 1) * sklearn.preprocessing.minmax_scale(spectrum_input)\n",
    "    out_spectrum = np.power(sklearn.preprocessing.minmax_scale(ampletude), 2) * sklearn.preprocessing.minmax_scale(spectrum_input)\n",
    "    \n",
    "    ##\n",
    "    ampletude = sklearn.preprocessing.minmax_scale(ampletude)\n",
    "    ampletude_true = sklearn.preprocessing.minmax_scale(ampletude_true) \n",
    "    \n",
    "    ##\n",
    "    plt.rc('font', family='serif', size=10)\n",
    "    #plt.figure(figsize=(4, 1))\n",
    "    #plt.title(\"Unmixed channel {}. Filner#{}\".format(unmixed_channel_number, filter_number))\n",
    "    #FINAL_AXIS[index, 0].plot(frequencies[:ZOOM], sklearn.preprocessing.minmax_scale(spectrum_input)[:ZOOM], label = 'input_spectruem')\n",
    "    FINAL_AXIS[index, 0].plot(frequencies[:ZOOM], sklearn.preprocessing.minmax_scale(ampletude_true)[:ZOOM], label = 'True', linewidth=1.5, marker=TRUE_MARKER, color=TRUE_COLOR, markevery=10)     \n",
    "    FINAL_AXIS[index, 0].plot(frequencies[:ZOOM], sklearn.preprocessing.minmax_scale(recovered)[:ZOOM], label = 'Patterns', linewidth=1.5, marker=PATTENS_MARKER, color=PATTENS_COLOR, markevery=10)\n",
    "    FINAL_AXIS[index, 0].plot(frequencies[:ZOOM], sklearn.preprocessing.minmax_scale(ampletude)[:ZOOM], label = 'Weights', color=WEIGHTS_COLOR, linewidth=1.5, marker=WEIGHTS_MARKER, markevery=10)\n",
    "\n",
    "    #plt.plot(frequencies[:ZOOM], sklearn.preprocessing.minmax_scale(out_spectrum)[:ZOOM], label = 'out_spectrum')\n",
    "    \n",
    "    \n",
    "    if index == 0:\n",
    "        FINAL_AXIS[index, 0].legend(bbox_to_anchor=(1, -5.4), ncol=4)\n",
    "\n",
    "    FINAL_AXIS[index, 0].grid()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_interpretable(X, W, Y):\n",
    "    y_col = Y.shape[1]\n",
    "    return np.linalg.multi_dot([\n",
    "        np.cov(X, rowvar=False), \n",
    "        W, \n",
    "        #np.linalg.inv(np.cov(Y, rowvar=False).reshape((y_col, y_col)))\n",
    "    ])\n",
    "\n",
    "\n",
    "interpret = get_interpretable(\n",
    "    np.copy(X_original),\n",
    "    np.copy(ica_weights_scaled),\n",
    "    np.copy(X_unmixed)\n",
    ")\n",
    "\n",
    "def get_ossagtchi_spatial_patterns(X, temproral_weights, spatial_weights):\n",
    "    patterns = np.zeros((spatial_weights.shape[0], spatial_weights.shape[1]))\n",
    "    for i in range(temproral_weights.shape[0]):\n",
    "        X_filtered = np.zeros(X.shape)\n",
    "        for j in range(X_filtered.shape[1]):\n",
    "            X_filtered[:, j] = np.convolve(X[:, j], temproral_weights[i, 0, :], mode=\"same\")\n",
    "        patterns[:, i] = np.dot(np.cov(X_filtered, rowvar=False), spatial_weights[:, i].reshape((-1, 1)))[:, 0]\n",
    "    return patterns\n",
    "\n",
    "interpret_ossadtchi = get_ossagtchi_spatial_patterns(\n",
    "    X_original,\n",
    "    convs_weights,\n",
    "    np.copy(ica_weights_scaled),\n",
    ")\n",
    "\n",
    "compare_weights(interpret_ossadtchi)\n",
    "\n",
    "\n",
    "print(\"Patters performance\")\n",
    "compare_weights(interpret)\n",
    "\n",
    "print(\"Ossadtchi Patters performance\")\n",
    "compare_weights(interpret_ossadtchi)\n",
    "\n",
    "\n",
    "# fig, axes = plt.subplots(2, 2)\n",
    "# fig.set_figwidth(8)\n",
    "# fig.set_figheight(4)\n",
    "# fig.tight_layout()\n",
    "\n",
    "METODS = [\"True\", \n",
    "          #\"Joined\",\n",
    "          \"Patterns\", \"Patterns naive\", \"Weights\", \n",
    "          #\"Quality\"\n",
    "         ]\n",
    "\n",
    "LS = [TRUE_MARKER, \n",
    "      #\".\",\n",
    "      PATTENS_MARKER,\n",
    "      PATTERNS_NAIVE_MARKER, \n",
    "      WEIGHTS_MARKER, \n",
    "      #\"o\"\n",
    "     ]\n",
    "\n",
    "LC = [TRUE_COLOR, PATTENS_COLOR, PATTERNS_NAIVE_COLOR, WEIGHTS_COLOR]\n",
    "\n",
    "\n",
    "\n",
    "for i in range(0, sources_dimension):\n",
    "    matrix = np.array([\n",
    "        mixing_matrix.transpose()[:, i],\n",
    "        interpret_ossadtchi[:, i],\n",
    "        interpret[:, i],\n",
    "        ica_weights[:, i],\n",
    "    ])\n",
    "    plt.rc('font', family='serif', size=12)\n",
    "    lines = sklearn.preprocessing.minmax_scale(np.abs(matrix), axis=1)\n",
    "    for line, label, line_style, line_color in list(zip(lines, METODS, LS, LC)):\n",
    "        if label == \"Joint\":\n",
    "            continue\n",
    "        FINAL_AXIS[i, 1].plot(line, label=label, linewidth=1 if label != \"True\" else 2, marker=line_style, color=line_color, markevery=1, markersize=None if label != \"True\" else 10)\n",
    "        FINAL_AXIS[i, 1].set_xticks(range(5))\n",
    "    \n",
    "    #axes[i // 2, i % 2].set_title(f\"Branch {i+1}\")\n",
    "    if i == 0:\n",
    "        plt.rc('font', family='serif', size=10)\n",
    "        FINAL_AXIS[i, 1].legend(bbox_to_anchor=(1, -5.4), ncol=4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
